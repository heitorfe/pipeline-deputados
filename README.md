# üèõÔ∏è Pipeline de Dados da C√¢mara dos Deputados

## Vis√£o Geral

Pipeline de dados end-to-end para an√°lise de gastos p√∫blicos e atividade parlamentar dos deputados federais brasileiros, utilizando dados abertos da API da C√¢mara dos Deputados. O projeto implementa uma arquitetura moderna de engenharia de dados com ingest√£o, transforma√ß√£o e visualiza√ß√£o automatizadas.

Link para a fonte dos dados: `https://dadosabertos.camara.leg.br/swagger/api.html?tab=api#staticfile`

---

## üõ†Ô∏è Stack Tecnol√≥gica

### Ingest√£o de Dados
- **Python**: Scripts para extra√ß√£o inicial completa dos dados hist√≥ricos  
- **Apache Airflow**: Orquestra√ß√£o da ingest√£o incremental di√°ria  
- **Pandas**: Manipula√ß√£o e transforma√ß√£o dos dados durante a extra√ß√£o  
- **Amazon S3**: Data Lake para armazenamento dos arquivos brutos em formato Parquet  

### Armazenamento e Processamento
- **Snowflake**: Data Warehouse principal com separa√ß√£o de ambientes (`RAW`, `STAGING`, `ANALYTICS`)  
- **Snowpipe**: Ingest√£o autom√°tica e incremental acionada por eventos do S3  
- **AWS IAM**: Configura√ß√£o de roles e pol√≠ticas de seguran√ßa para integra√ß√£o  

### Transforma√ß√£o de Dados
- **dbt (Data Build Tool)**: Modelagem dimensional e transforma√ß√µes ELT  
- **SQL**: Queries complexas para cria√ß√£o de dimens√µes e fatos  
- **dbt Seeds**: Carregamento de dados de refer√™ncia est√°ticos  

### Visualiza√ß√£o e An√°lise
- **Streamlit**: Dashboard interativo para an√°lise individual de deputados  
- **Plotly**: Gr√°ficos din√¢micos e visualiza√ß√µes avan√ßadas  
- **Snowflake Connector**: Conex√£o direta com o Data Warehouse  

---

## üèóÔ∏è Arquitetura do Projeto

### 1. Camada de Ingest√£o
- **Carga Inicial (Full Load)**: Scripts Python que consomem a API da C√¢mara dos Deputados para extrair dados hist√≥ricos completos de despesas, deputados, legislaturas e outros datasets  
- **Carga Incremental**: DAG do Airflow executada diariamente que:
  - Identifica deputados com mandato ativo  
  - Extrai despesas dos √∫ltimos dois meses  
  - Salva os dados em formato Parquet no S3  

### 2. Camada de Armazenamento
- **S3 Data Lake**: Armazenamento de arquivos brutos organizados por tipo e per√≠odo  
- **Snowpipe**: Detecta automaticamente novos arquivos no S3 e executa `COPY INTO` para carregar dados na tabela de staging  
- **Streams & Tasks**: Sistema de CDC (Change Data Capture) que detecta novos dados e executa `MERGE` para evitar duplicatas  

### 3. Camada de Transforma√ß√£o (dbt)
- **Staging Models**: Limpeza e padroniza√ß√£o dos dados brutos  
- **Dimension Models**: Cria√ß√£o de dimens√µes com SCD Type 2 para hist√≥rico de mudan√ßas  
- **Fact Models**: Tabelas de fatos com m√©tricas e chaves estrangeiras  
- **Mart Models**: Views anal√≠ticas para consumo do dashboard  

### 4. Camada de Apresenta√ß√£o
- **Dashboard Streamlit**: Interface interativa com:
  - An√°lise temporal de gastos  
  - Ranking por tipo de despesa  
  - Hist√≥rico pol√≠tico dos deputados  
  - Filtros din√¢micos por per√≠odo e partido  

---

## üìä Funcionalidades Implementadas

### Pipeline de Dados
- Ingest√£o automatizada de mais de 2 milh√µes de registros de despesas  
- Processamento incremental que evita reprocessamento desnecess√°rio  
- Monitoramento e alertas atrav√©s do Airflow UI  
- Qualidade de dados garantida por testes automatizados do dbt  

### Modelagem Dimensional
- **Dimens√£o Tempo**: Gerada automaticamente com hierarquias (ano, m√™s, trimestre)  
- **Dimens√£o Deputados**: SCD Type 2 para rastrear mudan√ßas de partido/estado  
- **Dimens√£o Fornecedores**: Normaliza√ß√£o de dados de prestadores de servi√ßos  
- **Fato Despesas**: Tabela central com todas as m√©tricas financeiras  

### Dashboard Anal√≠tico
- KPIs executivos (total gasto, n√∫mero de despesas, fornecedores √∫nicos)  
- An√°lises temporais com contexto hist√≥rico  
- Drill-down por tipo de despesa e fornecedor  
- Exporta√ß√£o de dados detalhados  

---

## üéØ Resultados e Impacto
- **Volume de Dados**: Processamento de ~2M registros de despesas desde 2019  
- **Performance**: Queries anal√≠ticas executadas em <2 segundos  
- **Automa√ß√£o**: Pipeline 100% automatizado com execu√ß√£o di√°ria  
- **Qualidade**: Cobertura de testes de qualidade de dados >90%  
- **Escalabilidade**: Arquitetura preparada para crescimento de volume e complexidade  

---

## üîß Configura√ß√µes T√©cnicas

### Integra√ß√£o Cloud
- Storage Integration entre Snowflake e S3  
- Event notifications do S3 para acionamento do Snowpipe  
- Configura√ß√£o de roles IAM para acesso seguro entre servi√ßos  

### Orquestra√ß√£o
- DAGs parametriz√°veis para diferentes per√≠odos de extra√ß√£o  
- Retry autom√°tico em caso de falhas na API  
- Logging detalhado para debugging e monitoramento  

### Qualidade de Dados
- Testes de integridade referencial  
- Valida√ß√£o de tipos e formatos  
- Monitoramento de freshness dos dados  
- Testes de *business rules* espec√≠ficos do dom√≠nio  

---

## üí° Diferenciais T√©cnicos
- **Arquitetura Event-Driven**: Uso do Snowpipe para ingest√£o reativa aos eventos do S3  
- **Processamento Incremental Inteligente**: Evita reprocessamento desnecess√°rio atrav√©s de controle de datas  
- **Modelagem Avan√ßada**: Implementa√ß√£o de SCD Type 2 para rastreamento hist√≥rico  
- **Observabilidade**: Monitoramento completo atrav√©s de logs estruturados e m√©tricas  

---

Este projeto demonstra dom√≠nio completo do ciclo de vida de dados, desde a extra√ß√£o at√© a apresenta√ß√£o, utilizando as melhores pr√°ticas de engenharia de dados e ferramentas modernas do mercado.
